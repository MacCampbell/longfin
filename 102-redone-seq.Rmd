---
title: "102-redone-seq"
author: "Mac Campbell"
date: "2022-12-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r}
library(tidyverse)
```

## Align and examine new data     
LFS1_S113_L006 LFS2_S114_L006
```{r}
meta<-read_csv("meta/NightSmLFS_Redband_sampledata.csv") %>% filter(Species %in% c("LarvalLFS","NightSmelt","LongfinSmelt")) %>% 
  mutate(Prefix=ifelse(Plate=="NightSmelt_LFS_Normalized_1","LFS1_S113_L006","LFS2_S114_L006"))

meta
```

batch rename, move to data/new-data     

```{r}
commands<-meta %>% mutate(Command1=paste0("mv /home/maccamp/missouri-trout/data/",Plate,"/",
                                          Prefix,"_RA_","GG",
                                          `WellBarcode`,"TGCAGG.fastq"," data/new-data/",
                                          `SampleID`,"_RA.fastq")) %>% 
  mutate(Command2=paste0("mv /home/maccamp/missouri-trout/data/",Plate,"/",
                         Prefix,"_RB_","GG",`WellBarcode`,"TGCAGG.fastq",
                                   " data/new-data/",`SampleID`,"_RB.fastq"))

c1<- select(commands, Command1) %>% rename(Command=Command1)
c2<- select(commands, Command2) %>% rename(Command=Command2)
c3 <- bind_rows(c1, c2)
write_tsv(c3, file="102.1-batch-rename.sh", col_names = FALSE)

```


```{sh, eval=FALSE}
ls | grep RA | perl -pe 's/.fastq//g' > forward
ls | grep RB | perl -pe 's/.fastq//g' > reverse
ls | grep RA | perl -pe 's/_RA.fastq//g' > name
paste forward reverse name  > samples.txt
bash $HOME/missouri-trout/doAlign-unzipped.sh samples.txt /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa 
```


Aligning 114 samples.......       

```{r}
existing<-read_tsv("meta/counts.tsv") %>% filter(Alignment !="Original")
existing<-existing %>% filter(Alignment=="New Genome") %>% filter(Reads > 1.5e5) %>%
  mutate(Path=paste0("/home/maccamp/data/longfin/",File))

ggplot(existing) + geom_histogram(aes(x=Reads))
```

```{r}
new<-read_csv("outputs/102/newseq.dat", col_names = c("Sample","Sort","Dedup"))

ggplot(new) + geom_histogram(aes(x=Dedup))
```
```{r}
together<-existing %>% select(-Alignment) %>% separate(Sample, into=c("Location","Number"), sep="_", remove=FALSE) %>% select(-Number)
new2<-new %>% mutate(File=paste0(Sample,".sort.flt.bam")) %>% rename(Reads=Dedup) %>% select(-Sort) %>%
  mutate(Path=paste0("data/new-data/",File)) %>% filter(Reads > 50000) %>%
  mutate(Location="New")

together<-together %>% bind_rows(new2)

write_csv(together, file="meta/188.csv")
write_tsv(select(together,Path), file="bamlists/188.bamlist", col_names = FALSE)

ggplot(together) +
  geom_histogram(aes(x=Reads, fill=Location))
```

```{sh, eval=FALSE}
srun -p high -t 14:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 24 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/188.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 160 \
  -out $HOME/longfin/outputs/102/188-min160 > outputs/102/beagle.out 2> outputs/102/beagle.err &
  
srun -p high -t 01:00:00 --nodes=1 python $HOME/pcangsd/pcangsd.py -beagle outputs/102/188-min160.beagle.gz \
   -admix -o outputs/102/188-pca -threads 10

#found bestk=4 @ minind 141
#best k =7 @ 150 inds
#best k=5 @160 inds

#50 % missing
srun -p high -t 14:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 24 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/188.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 94 \
  -out $HOME/longfin/outputs/102/188-min50 > outputs/102/beagle.out 2> outputs/102/beagle.err &
  
#IBS version

srun -p high -t 6:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/188.bamlist -doGLF 2 -minInd 94 \
  -minMapQ 10 -minQ 20 -GL 2 \
  -doMajorMinor 1 -doMaf 1 -SNP_pval 1e-3 \
  -doIBS 1 -doCounts 1 -doCov 1 -makeMatrix 1 -minMaf 0.05 \
  -out $HOME/longfin/outputs/102/188-min50-ibs-gl > outputs/102/188-ibs-gl.out 2> outputs/102/188-ibs-gl.err &

```

25028 sites, too much missing data with minind 141
trying minind 166, 911 sites
50 inds 137815 sites?
150 inds 	-> Number of sites retained after filtering: 8199    
160 inds 1858 sites        

```{r}
m <- as.matrix(read.table("outputs/102/188-min50-ibs-gl.covMat"))

meta<-read_csv("meta/188-edited.csv")
eig <- eigen(m)
var<-eig$values/sum(eig$values)
cumvar<-cumsum(eig$values)/sum(eig$values)

head(var)
head(cumvar)
covs<-eig$vectors[,1:3] %>% as_tibble() %>% bind_cols(meta)

text12<-covs %>% select(Sample, Loc, V1, V2) %>%
  group_by(Loc) %>% summarize(Count=n(), x=mean(V1), y=mean(V2))

covs12<-ggplot(covs) +
  geom_point(aes(x=V1, y=V2, fill=Loc), pch=21, alpha=0.75) +
  geom_text_repel(data=text12, aes(x=x, y=y, label=Loc), max.overlaps = Inf) +
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = "")) +
  ylab(paste("PC2", " ", round((100*var[2]),2), "%", sep = "")) +
  theme_bw() +
  theme(legend.position="")
covs12
```

```{r}
cov<-read_delim("outputs/102/188-pca.cov", col_names=FALSE, delim=" ") %>% as.matrix()
meta<-together

meta$Location<-factor(meta$Location, levels=c("YBAK","SKNA","New","PTLC","HRLC","FRAS","LWSH","COLR",
                                              "HUMB","SFBY","PETA","ALVS","SUIB","CHPI"))
```

```{r}
#' @param samples character vector with the individuals IDs in the order in which
#' they were passed in the bamlist to angsd.
#' @param cov covariance matrix
covar2pcs <- function(samples, cov) {
  
  
  eig <- eigen(cov, symm = TRUE)
  PC <- as.data.frame(eig$vectors) %>%
    as_tibble() %>%
    setNames(sprintf("PC-%02d", 1:ncol(.)))
  
  samtib <- tibble(sample = samples)
  
  list(
    PCs = bind_cols(samtib, PC),
    eigevalues = eig$values
  )
}
```

```{r}
pca <- covar2pcs(meta$Sample, cov)

pca_long <- pca$PCs %>%
  tidyr::gather(., key = "PC", "val", -sample)

# then expand a grid of the possible comparisons (ordered)
expg <- expand.grid(sample = pca$PCs$sample,
                    PCx = sprintf("PC-%02d", 1:6),
                    PCy = sprintf("PC-%02d", 1:6),
                    stringsAsFactors = FALSE) %>%
  tibble::as_tibble()

# then left join the pca results onto that
pca_pairs <- dplyr::left_join(expg, pca_long, by = c("sample", "PCx" = "PC")) %>%
  dplyr::rename(val_x = val) %>%
  dplyr::left_join(pca_long, by = c("sample", "PCy" = "PC")) %>%
  dplyr::rename(val_y = val)

pp_meta <- pca_pairs %>%   # just keep the first 6 PCs around
  left_join(., meta, by = c("sample" = "Sample")) %>%
  mutate(group = Location) 
```

Plot    

```{r}
npc <- 3
pp_meta2 <- pp_meta %>%
  filter( (PCx %in% sprintf("PC-%02d", 1:npc)) & 
            (PCy %in% sprintf("PC-%02d", 1:npc)) )

eig <- eigen(cov, symm = TRUE)
var<-eig$values/sum(eig$values)
cumvar<-cumsum(eig$values)/sum(eig$values)

head(var)
head(cumvar)
```

```{r}
ggplot(pp_meta2, aes(x = val_x, y = val_y, color=Location)) +
  geom_point() +
  facet_grid(PCx ~ PCy)
```

```{r}
sub12<-pp_meta2 %>% filter( (PCx =="PC-01") & (PCy =="PC-02") )
text<- sub12 %>% select(sample,Location,val_x,val_y) %>% group_by(Location) %>%
  mutate(meanX=mean(val_x), meanY=mean(val_y)) %>% select(Location, meanX, meanY) %>%
  unique()   

ggplot(sub12, aes(x = val_x, y = val_y, color=Location))+
  geom_point(size = 2, alpha=0.5) +
  geom_text_repel(data=text, aes(x=meanX, y=meanY, label=Location), max.overlaps = Inf) +
  scale_fill_discrete(na.value = "white") + 
  theme_bw()+
  theme(panel.grid=element_blank())+
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = ""))+
  ylab(paste("PC2", " ", round((100*var[2]),2), "%", sep = ""))+
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_viridis_d(option="C")

ggsave("outputs/102/lfs-dsm-reference-pc12.jpeg")
```

Ohh gross. Maybe I'll need to downsample again?


```{r}
together %>% filter(Location == "New") %>% summarize(Mean=mean(Reads))
together %>% filter(Location != "New") %>% summarize(Mean=mean(Reads))
```

Downsample to 150K?    

```{r}
downsample<-read_tsv("meta/counts.tsv") %>% filter(Alignment !="Original") %>% filter(Reads > 1e5) %>%
  mutate(Frac=1e5/Reads) %>%
  mutate(ReductionCommand = paste0("samtools view -bs ",Frac, " ", "/home/maccamp/data/longfin/",
                                   Sample, "_R1.sort.flt.bam"," > ",
                                   "/home/maccamp/longfin/data/reduced/",
                                   Sample,".reduced.bam" )) %>%
  mutate(newPath= paste0("data/reduced/",Sample,".reduced.bam" ))

write_csv(downsample$ReductionCommand %>% as_tibble(), "102.1-downsample.sh", col_names = FALSE)
```

running like so:
(base) maccamp@farm:~/longfin$ srun -p high -time 01:00:00 --nodes=1 parallel -j 10 < 102.1-downsample.sh 


```{r}
lfs<-downsample %>% select(-Alignment,-ReductionCommand) %>%
  separate(Sample, into=c("Location","Number"), sep="_", remove=FALSE) %>% select(-Number) %>%
  rename(Path=newPath)


lfs<-lfs %>% bind_rows(new2%>%filter(Reads > 75000) %>% mutate(Frac=1))
write_csv(lfs,file="meta/175-sub-meta.csv")

write_tsv(select(lfs,Path), file="bamlists/175-sub.bamlist", col_names = FALSE)

ggplot(lfs) +
  geom_histogram(aes(x=(Frac*Reads), fill=Location)) +
  xlim(0,3.5e5)
```

```{sh, eval=FALSE}
srun -p high -t 14:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 24 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/193-sub.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 145 \
  -out $HOME/longfin/outputs/102/193-sub> outputs/102/beagle.out 2> outputs/102/beagle.err &
  
srun -p high -t 01:00:00 --nodes=1 python $HOME/pcangsd/pcangsd.py -beagle outputs/102/193-sub.beagle.gz \
   -admix -o outputs/102/193-sub-pca -threads 10
   
   
srun -p high -t 14:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/193-sub.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 97 \
  -out $HOME/longfin/outputs/102/193-sub50> outputs/102/beagle50.out 2> outputs/102/beagle50.err &
  
srun -p high -t 01:00:00 --nodes=1 python $HOME/pcangsd/pcangsd.py -beagle outputs/102/193-sub50.beagle.gz \
   -admix -o outputs/102/193-sub50-pca -threads 10
   
srun -p high -t 14:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/175-sub.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 88 \
  -out $HOME/longfin/outputs/102/175-sub50> outputs/102/beagle50.out 2> outputs/102/beagle50.err &


   
srun -p bigmemh -t 8:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/175-sub.bamlist -GL 1 -r lg01 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -minInd 149 \
  -out $HOME/longfin/outputs/102/175-sub95> outputs/102/beagle95.out 2> outputs/102/beagle95.err &

#  -rf $HOME/delta-smelt/metadata/large-contigs.txt
#lg01 has 0 sites at 0.95
#lg01 has 0 sites at 0.9
#lg01 has sites at 0.85
  
srun -p high -t 01:00:00 --nodes=1 python $HOME/pcangsd/pcangsd.py -beagle outputs/102/175-sub50.beagle.gz \
   -admix -o outputs/102/175-sub50-pca -threads 10
```


2378 sites when using 100k read depth and 75% threshold.   
19766 with 50% threshold, new samples still crappy. Removing < 75K read samples and trying again.    

```{r}
cov<-read_delim("outputs/102/175-sub50-pca.cov", col_names=FALSE, delim=" ") %>% as.matrix()
meta<-lfs

meta$Location<-factor(meta$Location, levels=c("YBAK","SKNA","New","PTLC","HRLC","FRAS","LWSH","COLR",
                                             "HUMB","SFBY","PETA","ALVS","SUIB","CHPI"))
```

```{r}
pca <- covar2pcs(meta$Sample, cov)

pca_long <- pca$PCs %>%
  tidyr::gather(., key = "PC", "val", -sample)

# then expand a grid of the possible comparisons (ordered)
expg <- expand.grid(sample = pca$PCs$sample,
                    PCx = sprintf("PC-%02d", 1:6),
                    PCy = sprintf("PC-%02d", 1:6),
                    stringsAsFactors = FALSE) %>%
  tibble::as_tibble()

# then left join the pca results onto that
pca_pairs <- dplyr::left_join(expg, pca_long, by = c("sample", "PCx" = "PC")) %>%
  dplyr::rename(val_x = val) %>%
  dplyr::left_join(pca_long, by = c("sample", "PCy" = "PC")) %>%
  dplyr::rename(val_y = val)

pp_meta <- pca_pairs %>%   # just keep the first 6 PCs around
  left_join(., meta, by = c("sample" = "Sample")) %>%
  mutate(group = Location) 

npc <- 3
pp_meta2 <- pp_meta %>%
  filter( (PCx %in% sprintf("PC-%02d", 1:npc)) & 
            (PCy %in% sprintf("PC-%02d", 1:npc)) )

eig <- eigen(cov, symm = TRUE)
var<-eig$values/sum(eig$values)
cumvar<-cumsum(eig$values)/sum(eig$values)

head(var)
head(cumvar)
```

```{r}
ggplot(pp_meta2, aes(x = val_x, y = val_y, color=Location)) +
  geom_point() +
  facet_grid(PCx ~ PCy)
```


```{r}
sub12<-pp_meta2 %>% filter( (PCx =="PC-01") & (PCy =="PC-02") )
text<- sub12 %>% select(sample,Location,val_x,val_y) %>% group_by(Location) %>%
  mutate(meanX=mean(val_x), meanY=mean(val_y)) %>% select(Location, meanX, meanY) %>%
  unique()   

ggplot(sub12, aes(x = val_x, y = val_y, color=Location))+
  geom_point(size = 2, alpha=0.5) +
  geom_text_repel(data=text, aes(x=meanX, y=meanY, label=Location), max.overlaps = Inf) +
  scale_fill_discrete(na.value = "white") + 
  theme_bw()+
  theme(panel.grid=element_blank())+
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = ""))+
  ylab(paste("PC2", " ", round((100*var[2]),2), "%", sep = ""))+
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_viridis_d(option="C")

ggsave("outputs/102/lfs-dsm-reference-pc12-downsample.jpeg")
```

## Probs:
(1) Maybe need to use ANGSD to generate a covariance matrix.
(2) Maybe need to downsample locations a bit to see if that helps. 
(3) Check "new" samples and see what they have going on?

```{r}
new2 %>% filter(Reads > 75000)
new3<-new2 %>% filter(Reads > 75000)

```

48 samples:
```{r}
write_tsv(new2 %>% select(Path), col_names = FALSE, file="bamlists/48.bamlist")
```

30 sample:

```{r}
write_tsv(new3 %>% select(Path), col_names = FALSE, file="bamlists/30.bamlist")
```

```{sh, eval=FALSE}
srun -p high -t 10:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/48.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 24 \
  -out $HOME/longfin/outputs/102/48-sub50> outputs/102/beagle50.out 2> outputs/102/beagle50.err &


srun -p high -t 01:00:00 --nodes=1 python $HOME/pcangsd/pcangsd.py  \
   -beagle outputs/102/48-sub50.beagle.gz \
   -admix -o outputs/102/48-sub50-pca -threads 10
   
   
srun -p high -t 10:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/30.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 15 \
  -out $HOME/longfin/outputs/102/30-sub50> outputs/102/beagle50.out 2> outputs/102/beagle50.err &


srun -p high -t 01:00:00 --nodes=1 python $HOME/pcangsd/pcangsd.py  \
   -beagle outputs/102/30-sub50.beagle.gz \
   -admix -o outputs/102/30-sub50-pca -threads 10
   
srun -p high -t 10:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/30.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 22 \
  -out $HOME/longfin/outputs/102/30-sub75> outputs/102/beagle75.out 2> outputs/102/beagle75.err &

srun -p high -t 01:00:00 --nodes=1 python $HOME/pcangsd/pcangsd.py  \
   -beagle outputs/102/30-sub75.beagle.gz \
   -admix -o outputs/102/30-sub75-pca -threads 10
```
     
2255 Sites with 48 (50K)      
2893 sites with 30 (75K)
1187 sites with 30 at 75% missing


```{r}
cov<-read_delim("outputs/102/30-sub75-pca.cov", col_names=FALSE, delim=" ") %>% as.matrix()
meta<-new3 %>% separate(Sample, into=c("Loc","Num1","Num2"), remove = FALSE)
```

```{r}
pca <- covar2pcs(meta$Sample, cov)

pca_long <- pca$PCs %>%
  tidyr::gather(., key = "PC", "val", -sample)

# then expand a grid of the possible comparisons (ordered)
expg <- expand.grid(sample = pca$PCs$sample,
                    PCx = sprintf("PC-%02d", 1:6),
                    PCy = sprintf("PC-%02d", 1:6),
                    stringsAsFactors = FALSE) %>%
  tibble::as_tibble()

# then left join the pca results onto that
pca_pairs <- dplyr::left_join(expg, pca_long, by = c("sample", "PCx" = "PC")) %>%
  dplyr::rename(val_x = val) %>%
  dplyr::left_join(pca_long, by = c("sample", "PCy" = "PC")) %>%
  dplyr::rename(val_y = val)

pp_meta <- pca_pairs %>%   # just keep the first 6 PCs around
  left_join(., meta, by = c("sample" = "Sample")) %>%
  mutate(group = Location) 

npc <- 3
pp_meta2 <- pp_meta %>%
  filter( (PCx %in% sprintf("PC-%02d", 1:npc)) & 
            (PCy %in% sprintf("PC-%02d", 1:npc)) )

eig <- eigen(cov, symm = TRUE)
var<-eig$values/sum(eig$values)
cumvar<-cumsum(eig$values)/sum(eig$values)

head(var)
head(cumvar)
```

```{r}
ggplot(pp_meta2, aes(x = val_x, y = val_y, color=Loc)) +
  geom_point() +
  facet_grid(PCx ~ PCy)
```


```{r}
sub12<-pp_meta2 %>% filter( (PCx =="PC-01") & (PCy =="PC-02") )
text<- sub12 %>% select(sample,Loc,val_x,val_y) %>% group_by(Loc) %>%
  mutate(meanX=mean(val_x), meanY=mean(val_y)) %>% select(Loc, meanX, meanY) %>%
  unique()   

ggplot(sub12, aes(x = val_x, y = val_y, color=Loc))+
  geom_point(size = 2, alpha=0.5) +
  geom_text_repel(data=text, aes(x=meanX, y=meanY, label=Loc), max.overlaps = Inf) +
  scale_fill_discrete(na.value = "white") + 
  theme_bw()+
  theme(panel.grid=element_blank())+
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = ""))+
  ylab(paste("PC2", " ", round((100*var[2]),2), "%", sep = ""))+
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_viridis_d(option="C")

```


Single read sampling approach:
http://www.popgen.dk/angsd/index.php/PCA_MDS     

```{sh, eval=FALSE}
./angsd -bam all.files -minMapQ 30 -minQ 20 -GL 2  -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 -doIBS 1 -doCounts 1 -doCov 1 -makeMatrix 1 -minMaf 0.05 -P 5
```

"This will produce the output (see below) which includes pairwise differences (.ibsMat) and the covariance matrix (.covMat). These can be used for MDS and PCA respectively (see R example below). Note that only the PCA method require SNP calling and allele frequency estimation."       

```{sh, eval=FALSE}

srun -p high -t 6:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/48.bamlist \
  -minMapQ 30 -minQ 20 -GL 2 \
  -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 \
  -doIBS 1 -doCounts 1 -doCov 1 -makeMatrix 1 -minMaf 0.05 \
  -out $HOME/longfin/outputs/102/48-ibs > outputs/102/ibs.out 2> outputs/102/ibs.err &


srun -p high -t 6:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/48.bamlist -doGLF 2 -minInd 24 \
  -minMapQ 30 -minQ 20 -GL 2 \
  -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 \
  -doIBS 1 -doCounts 1 -doCov 1 -makeMatrix 1 -minMaf 0.05 \
  -out $HOME/longfin/outputs/102/48-ibs-gl > outputs/102/ibs-gl.out 2> outputs/102/ibs-gl.err &
```

	-> Number of sites retained after filtering: 64363     
	-> Number of sites retained after filtering: 1903 (lost sepeartion of samples here)

```{r}
covm<-new2 %>% separate(Sample, into=c("Loc","Num1","Num2"), remove = FALSE)
covm
```

```{r}
m <- as.matrix(read.table("outputs/102/48-ibs.ibsMat"))
mds <- cmdscale(as.dist(m))
plot(mds,lwd=2,ylab="Dist",xlab="Dist",main="multidimensional scaling")
```
```{r}
m <- as.matrix(read.table("outputs/102/48-ibs.covMat"))
e <- eigen(m)
plot(e$vectors[,1:2],lwd=2,ylab="PC 2",xlab="PC 2",main="Principal components",pch=16)
```
```{r}
covs<-e$vectors[,1:2] %>% as_tibble() %>% bind_cols(covm)
ggplot(covs) +
  geom_point(aes(x=V1, y=V2, fill=Loc), pch=21)
```
It kinda works.....


heatmap / clustering / trees
```{r}
name <- "outputs/102/48-ibs.covMat" # or covMat
m <- as.matrix(read.table(name))

#heat map
heatmap(m)

#neighbour joining
plot(ape::nj(m))

#plot(hclust(dist(m), "ave")

```
Can I generate a GL file with doIbs? I can, but I don't know what it is doing.    


```{sh, eval=FALSE}
srun -p high -t 6:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/175-sub.bamlist -doGLF 2 -minInd 88 \
  -minMapQ 10 -minQ 20 -GL 2 \
  -doMajorMinor 1 -doMaf 1 -SNP_pval 1e-3 \
  -doIBS 1 -doCounts 1 -doCov 1 -makeMatrix 1 -minMaf 0.05 \
  -out $HOME/longfin/outputs/102/175-ibs-gl > outputs/102/ibs-gl.out 2> outputs/102/ibs-gl.err &
```

	-> Number of sites retained after filtering: 27421, this gives us 4000 more snps than before.
	
```{r}
covm<-lfs %>% separate(Sample, into=c("Loc","Num1","Num2"), remove = FALSE)
m <- as.matrix(read.table("outputs/102/175-ibs-gl.covMat"))
e <- eigen(m)
covs<-e$vectors[,1:2] %>% as_tibble() %>% bind_cols(covm)
ggplot(covs) +
  geom_point(aes(x=V1, y=V2, fill=Loc), pch=21) +
  theme_bw()
```

```{r}
ggplot(covs) +
  geom_point(aes(x=V1, y=V2, fill=Loc), pch=21) +
  facet_wrap(.~Location)
```


## Trim FASTQs to 100bp each
in new-data-trim

module load seqtk

seqtk trimfq -e 35 in.fastq > out.fastq

My forward are 135 bp in length theirs are 85, trimming 50 bp
My reverse are 151 bp in length, theirs are 101, trimming 50 bp
```{r}
m1<-read_csv("meta/NightSmLFS_Redband_sampledata.csv") %>% filter(Species %in% c("LarvalLFS","NightSmelt","LongfinSmelt")) %>% 
  mutate(Prefix=ifelse(Plate=="NightSmelt_LFS_Normalized_1","LFS1_S113_L006","LFS2_S114_L006"))

rename<-m1 %>% mutate(r1=paste0("seqtk trimfq -e 50 data/new-data/",
                                          `SampleID`,"_RA.fastq > data/new-data-trim/", `SampleID`,"_RA.fastq")) %>% 
  mutate(r2=paste0("seqtk trimfq -e 50 data/new-data/",
                         `SampleID`,"_RB.fastq > data/new-data-trim/",`SampleID`,"_RB.fastq"))

r1<- select(rename, r1) %>% rename(Command=r1)
r2<- select(rename, r2) %>% rename(Command=r2)
r3 <- bind_rows(r1, r2)
r3
write_tsv(r3, "102.2-batch-trim.sh",col_names = FALSE)
```


Trim and re-align
```{sh, eval=FALSE}
ls | grep RA | perl -pe 's/.fastq//g' > forward
ls | grep RB | perl -pe 's/.fastq//g' > reverse
ls | grep RA | perl -pe 's/_RA.fastq//g' > name
paste forward reverse name  > samples.txt
bash $HOME/missouri-trout/doAlign-unzipped.sh samples.txt /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa 
```

m1 has 114 samples.

