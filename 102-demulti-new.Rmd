---
title: "102-demulti-new"
author: "Mac Campbell"
date: "8/22/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r}
library(tidyverse)
```

## Demulti new samples

Counting lines in the files to make sure demulti was complete. For example:
 awk '{l++} END {print l/4}' LibPlate25_MORedband02_R1.fastq
 
 l004:
gunzip -c BMAG072_S1_L004_R1_001.fastq.gz |  awk '{l++} END {print l/4}'
cat *R1.fastq | awk '{l++} END {print l/4}' 
These are 


We have three plates in two lanes. Due to space constraints, they are in two locations. 

Checking completeness:
`(base) maccamp@farm:/group/millermrgrp4/maccamp/alanas-trout-2$  gunzip -c BMAG072_S1_L004_R1_001.fastq.gz |  awk '{l++} END {print l/4}'`
2947604505    

__1__ Combine into one file     

Doing in data/combined-plates   

```{sh, eval=FALSE}
cat /group/millermrgrp4/maccamp/alanas-trout/LibPlate21_LongfinSmelt01_R1.fastq          /group/millermrgrp4/maccamp/alanas-trout-2/LibPlate21_LongfinSmelt01_R1.fastq > longfin-01_R1.fastq &

cat /group/millermrgrp4/maccamp/alanas-trout/LibPlate22_LongfinSmelt02_R1.fastq          /group/millermrgrp4/maccamp/alanas-trout-2/LibPlate22_LongfinSmelt02_R1.fastq > longfin-02_R1.fastq &

cat /group/millermrgrp4/maccamp/alanas-trout/LibPlate23_LongfinSmelt03_R1.fastq          /group/millermrgrp4/maccamp/alanas-trout-2/LibPlate23_LongfinSmelt03_R1.fastq > longfin-03_R1.fastq &


cat /group/millermrgrp4/maccamp/alanas-trout/LibPlate21_LongfinSmelt01_R2.fastq          /group/millermrgrp4/maccamp/alanas-trout-2/LibPlate21_LongfinSmelt01_R2.fastq > longfin-01_R2.fastq &

cat /group/millermrgrp4/maccamp/alanas-trout/LibPlate22_LongfinSmelt02_R2.fastq          /group/millermrgrp4/maccamp/alanas-trout-2/LibPlate22_LongfinSmelt02_R2.fastq > longfin-02_R2.fastq &

cat /group/millermrgrp4/maccamp/alanas-trout/LibPlate23_LongfinSmelt03_R2.fastq          /group/millermrgrp4/maccamp/alanas-trout-2/LibPlate23_LongfinSmelt03_R2.fastq > longfin-03_R2.fastq &
```

__2__ demultiplex each plate
      Checking for barcodes
      grep GGACAAGCTATGCAGG --color longfin-03_R1.fastq (works)
      barcode is ACAAGCTA
      
      separate dirs in data/   
      Using column 2 identifier and column 9    
These are now in /group/millermrgrp4/maccamp/longfin/plate-*


```{sh, eval=FALSE}
    cat /home/maccamp/longfin/meta/sample-meta.tsv | grep "Plate 1" | awk '{ print " perl ./BarcodeSplitListBestRadPairedEnd.pl", "longfin-01_R1.fastq", "longfin-01_R2.fastq", "GG"$9"TGCAGG", $2 }' > tasks.sh  
             srun -p high -t 1-10:00:00 --nodes=1 parallel -j 12 < tasks.sh > std.out 2>std.err &   

      cat /home/maccamp/longfin/meta/sample-meta.tsv | grep "Plate 2" | awk '{ print " perl ./BarcodeSplitListBestRadPairedEnd.pl", "longfin-02_R1.fastq", "longfin-02_R2.fastq", "GG"$9"TGCAGG", $2 }' > tasks.sh  
           srun -p high -t 1-10:00:00 --nodes=1 parallel -j 12 < tasks.sh > std.out 2>std.err &   

     
      cat /home/maccamp/longfin/meta/sample-meta.tsv | grep "Plate 3" | awk '{ print " perl ./BarcodeSplitListBestRadPairedEnd.pl", "longfin-03_R1.fastq", "longfin-03_R2.fastq", "GG"$9"TGCAGG", $2 }' > tasks.sh  
      srun -p high -t 1-10:00:00 --nodes=1 parallel -j 12 < tasks.sh > std.out 2>std.err &   
```
      
      
## Alignment

Previously, I used the non-accessioned genome.

`(base) maccamp@farm:~/data/longfin$ samtools view -H ALVS_097_R1.sort.bam`
`@HD	VN:1.5	SO:coordinate`
`@SQ	SN:lg01	LN:12516727`
`@SQ	SN:lg02	LN:17206656`
`@SQ	SN:lg03	LN:15692960`
`bwa mem /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa ALVS_097_R1.fastq.gz ALVS_097_R2.fastq.gz`

in each data/plate-x

ls | grep RA | perl -pe 's/.fastq//g' > forward 
ls | grep RB | perl -pe 's/.fastq//g' > reverse
ls | grep RA | cut -f 1-2 -d "_" > names
paste forward reverse names  > files.txt


bash /home/maccamp/longfin/scripts/doAlign-unzipped.sh files.txt /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa

Summarizing counts for each plate.

```{sh, eval=FALSE}
ls | grep sort.flt.bam | grep -v bai | while read line; do samtools flagstat $line | grep mapped | head -n 1 >> counts.txt; done;
ls | grep sort.bam | grep -v bai | while read line; do samtools flagstat $line | grep mapped | head -n 1 >> counts-sort.txt; done;
ls | grep sort.flt.bam | grep -v bai >> counts.files.txt

 paste counts.files.txt counts-sort.txt counts.txt | perl -pe 's/\s\+\s0\smapped\s\(/\t/g' | perl -pe 's/% : N\/A\)//g' > plate1.txt

 paste counts.files.txt counts-sort.txt counts.txt | perl -pe 's/\s\+\s0\smapped\s\(/\t/g' | perl -pe 's/% : N\/A\)//g' > plate2.txt

 paste counts.files.txt counts-sort.txt counts.txt | perl -pe 's/\s\+\s0\smapped\s\(/\t/g' | perl -pe 's/% : N\/A\)//g' > plate3.txt

```

```{r}
readFiles<-function(file) {
  fdf<-read_tsv(file, col_names=c("Bam","AlignedReads","PercentAligned","DedupReads"))
  return(fdf)
}
```

```{r}
files<-list.files(path="outputs/102", pattern=".txt", full.names = TRUE)
fdfs<-bind_rows(readFiles(files)) %>% select(-X5)
fdfs$Identifier<-gsub(".sort.flt.bam","",fdfs$Bam)
fdfs
```

Bind meta     

```{r}
meta<-read_tsv("meta/sample-meta.tsv") %>% left_join(fdfs) 

meta
```

```{r}
meta %>% group_by(`Common Name`) %>% summarize(Count=n())
```

```{r}
ggplot(meta) +
  geom_histogram(aes(x=DedupReads,fill=`Common Name`)) +
  scale_fill_viridis_d(option = 'turbo') +
  theme_bw() +
  theme(panel.grid=element_blank()) +
  ylab("Count") +
  xlab("Filtered Read Count")
```


```{r}
meta %>% group_by(`Common Name`) %>% summarize(Mean=mean(DedupReads))
```

```{r}
initial<-meta %>% filter(DedupReads > 150000)
initial %>% group_by(`Common Name`) %>% summarize(Count=n())
```

```{r}
ggplot(initial) +
  geom_histogram(aes(x=DedupReads,fill=`Common Name`)) +
  scale_fill_viridis_d(option = 'turbo') +
  theme_bw() +
  theme(panel.grid=element_blank()) +
  ylab("Count") +
  xlab("Filtered Read Count")

```

Need to downsample, to 1.75M?

```{r}
downsize<-initial %>% filter(DedupReads>1.75e6) %>% mutate(Fraction=1.75e6/DedupReads) %>% select(Identifier, Bam, Fraction) %>% mutate(Command=paste0("samtools view -bs ",Fraction," ",Bam," >",Identifier,".reduced.sort.flt.bam")) %>% select(Command)

write_tsv(downsize, "102.1-downsize-commands.sh", col_names = FALSE)
```
in bams/
srun -p high --nodes=1 -t 1:00:00 parallel -j 8 < ../102.1-downsize-commands.sh > downsize.stdout 2> downsize.stderr   
then: `(base) maccamp@farm:~/longfin/bams$ for f in *reduced.sort.flt.bam; do samtools index $f; done;`

Create initial bamlist

```{r}
d1<-initial %>% mutate(Path=ifelse(DedupReads<=1.75e6, paste0("bams/",Bam), paste0("bams/",Identifier,".reduced.sort.flt.bam")))
d1 %>% select(Path)
```

```{r}
write_tsv(d1 %>% select(Path), col_names = FALSE, "bamlists/initial179.bamlist")
```

Initial PCA
```{sh, eval=FALSE}
srun -p high -t 14:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 8 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/initial179.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-6 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -r lg01 -minInd 143 \
  -out $HOME/longfin/outputs/102/initial-lg01 > outputs/102/beagle-lg01.out 2> outputs/102/beagle-lg01.err &

```

9320 snps on lg01    

  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 112 \

Make covariance matrix.    
```{sh, eval=FALSE}
srun -p high -t 00:30:00 --nodes=1 python $HOME/pcangsd/pcangsd.py -beagle outputs/102/initial-lg01.beagle.gz \
    -o outputs/102/initial-pca -threads 10
```



```{r}
meta<-initial
```

```{r}
cov<-read_delim("outputs/102/initial-pca.cov", col_names=FALSE, delim=" ") %>% as.matrix()
```

```{r}
#' @param samples character vector with the individuals IDs in the order in which
#' they were passed in the bamlist to angsd.
#' @param cov covariance matrix
covar2pcs <- function(samples, cov) {
  
  
  eig <- eigen(cov, symm = TRUE)
  PC <- as.data.frame(eig$vectors) %>%
    as_tibble() %>%
    setNames(sprintf("PC-%02d", 1:ncol(.)))
  
  samtib <- tibble(sample = samples)
  
  list(
    PCs = bind_cols(samtib, PC),
    eigevalues = eig$values
  )
}
```


```{r}
pca <- covar2pcs(meta$Identifier, cov)

pca_long <- pca$PCs %>%
  tidyr::gather(., key = "PC", "val", -sample)

# then expand a grid of the possible comparisons (ordered)
expg <- expand.grid(sample = pca$PCs$sample,
                    PCx = sprintf("PC-%02d", 1:6),
                    PCy = sprintf("PC-%02d", 1:6),
                    stringsAsFactors = FALSE) %>%
  tibble::as_tibble()

# then left join the pca results onto that
pca_pairs <- dplyr::left_join(expg, pca_long, by = c("sample", "PCx" = "PC")) %>%
  dplyr::rename(val_x = val) %>%
  dplyr::left_join(pca_long, by = c("sample", "PCy" = "PC")) %>%
  dplyr::rename(val_y = val)

pp_meta <- pca_pairs %>%   # just keep the first 6 PCs around
  left_join(., meta, by = c("sample" = "Identifier")) %>%
  mutate(group = Location) 
```



Plot    

```{r}
npc <- 3
pp_meta2 <- pp_meta %>%
  filter( (PCx %in% sprintf("PC-%02d", 1:npc)) & 
            (PCy %in% sprintf("PC-%02d", 1:npc)) )

eig <- eigen(cov, symm = TRUE)
var<-eig$values/sum(eig$values)
cumvar<-cumsum(eig$values)/sum(eig$values)

head(var)
head(cumvar)
```


```{r}
ggplot(pp_meta2, aes(x = val_x, y = val_y, color=`Common Name`)) +
  geom_point() +
  facet_grid(PCx ~ PCy)
```