---
title: "104-report"
author: "Mac Campbell"
date: "2022-12-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r}
library(tidyverse)
library(ggrepel)
library(ggpubr)
library(adegenet)
library(vcfR)
```
     
Some ideas:

Reads available after aligning to DSM genome and de novo assembly.

Reads available as function of DNA amount.

# Where do the new samples end up


```{r}
lfs<-read_csv("meta/175-sub-meta.csv") %>% separate(Sample, into=c("Pre","Num1","Num2"), remove = FALSE)

new<-lfs %>% filter(Pre %in% c("19","20","Nksk")) %>% mutate(Collection=paste0(Pre,"-",Num1)) %>% select(-Location) %>%
  relocate(Collection) %>%
  mutate(Location=ifelse(Collection %in% c("19-0222","19-0225"),"EURS",
                  ifelse(Collection %in% c("20-1325","20-1329","20-1330","20-1373","20-1375"),"EELR",
                  ifelse(Collection %in% c("20-1291"), "KLAMR",
                  ifelse(Collection %in% c("20-1356"), "MADR",
                  ifelse(Collection %in% c("Nksk-2018"),"NOOK","None"))))))

comb<-lfs %>% filter(!Pre %in% c("19","20","Nksk")) %>% bind_rows(new)

```

```{r}
cov<-read_delim("outputs/102/175-sub50-pca.cov", col_names=FALSE, delim=" ") %>% as.matrix()
meta<-comb
meta$Location<-factor(meta$Location, levels=c("YBAK","SKNA","PTLC","HRLC","FRAS","NOOK","LWSH","COLR",
                                             "KLAMR","EURS","EELR","MADR","HUMB","SFBY","PETA","ALVS","SUIB","CHPI"))
```

```{r}
pca <- covar2pcs(meta$Sample, cov)

pca_long <- pca$PCs %>%
  tidyr::gather(., key = "PC", "val", -sample)

# then expand a grid of the possible comparisons (ordered)
expg <- expand.grid(sample = pca$PCs$sample,
                    PCx = sprintf("PC-%02d", 1:6),
                    PCy = sprintf("PC-%02d", 1:6),
                    stringsAsFactors = FALSE) %>%
  tibble::as_tibble()

# then left join the pca results onto that
pca_pairs <- dplyr::left_join(expg, pca_long, by = c("sample", "PCx" = "PC")) %>%
  dplyr::rename(val_x = val) %>%
  dplyr::left_join(pca_long, by = c("sample", "PCy" = "PC")) %>%
  dplyr::rename(val_y = val)

pp_meta <- pca_pairs %>%   # just keep the first 6 PCs around
  left_join(., meta, by = c("sample" = "Sample")) %>%
  mutate(group = Location) 

npc <- 3
pp_meta2 <- pp_meta %>%
  filter( (PCx %in% sprintf("PC-%02d", 1:npc)) & 
            (PCy %in% sprintf("PC-%02d", 1:npc)) )

eig <- eigen(cov, symm = TRUE)
var<-eig$values/sum(eig$values)
cumvar<-cumsum(eig$values)/sum(eig$values)

head(var)
head(cumvar)
```

```{r}
ggplot(pp_meta2, aes(x = val_x, y = val_y, color=Location)) +
  geom_point() +
  facet_grid(PCx ~ PCy)
```

```{r}
sub12<-pp_meta2 %>% filter( (PCx =="PC-01") & (PCy =="PC-02") )
text<- sub12 %>% select(sample,Location,val_x,val_y) %>% group_by(Location) %>%
  mutate(meanX=mean(val_x), meanY=mean(val_y)) %>% select(Location, meanX, meanY) %>%
  unique()   

pc12<-ggplot(sub12, aes(x = val_x, y = val_y, color=Location))+
  geom_point(size = 2, alpha=0.5) +
  geom_label_repel(data=text, aes(x=meanX, y=meanY, label=Location), max.overlaps = Inf) +
  scale_fill_discrete(na.value = "white") + 
  theme_bw()+
  theme(panel.grid=element_blank())+
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = ""))+
  ylab(paste("PC2", " ", round((100*var[2]),2), "%", sep = ""))+
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_viridis_d(option="H") +
  theme(legend.position = "")

sub13<-pp_meta2 %>% filter( (PCx =="PC-01") & (PCy =="PC-03") )
text<- sub13 %>% select(sample,Location,val_x,val_y) %>% group_by(Location) %>%
  mutate(meanX=mean(val_x), meanY=mean(val_y)) %>% select(Location, meanX, meanY) %>%
  unique()   

pc13<-ggplot(sub13, aes(x = val_x, y = val_y, color=Location))+
  geom_point(size = 2, alpha=0.5) +
  geom_label_repel(data=text, aes(x=meanX, y=meanY, label=Location), max.overlaps = Inf) +
  scale_fill_discrete(na.value = "white") + 
  theme_bw()+
  theme(panel.grid=element_blank())+
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = ""))+
  ylab(paste("PC3", " ", round((100*var[3]),2), "%", sep = ""))+
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_viridis_d(option="H") +
  theme(legend.position = "")
```

```{r}
ggarrange(pc12, pc13)

ggsave("outputs/104/longfin175-pc123.jpeg", width=10, height=5)
```
```{r}
meta %>% group_by(Location) %>% summarize(Count=n(), AvgReads=mean(Reads)) %>% arrange(AvgReads)
```

```{r}
new<-meta %>% filter(Location %in% c("KLAMR","EURS","EELR","MADR","NOOK"))
ggplot(new) +
  geom_histogram(aes(x=Reads, fill=Collection))

new %>% filter(Location=="NOOK") %>% select(Reads)
```

## IBS version

```{sh, eval=FALSE}
srun -p high -t 14:00:00 --mem=16G --nodes=1 $HOME/angsd/angsd -P 36 \
  -ref /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
  -bam $HOME/longfin/bamlists/175-sub.bamlist -GL 1 \
  -doGLF 2 -doMajorMinor 1 -doMaf 2 -SNP_pval 1e-3 -minMapQ 10 -minQ 20 -minMaf 0.05 \
  -rf $HOME/delta-smelt/metadata/large-contigs.txt  -minInd 88 \
  -out $HOME/longfin/outputs/102/175-sub50> outputs/102/beagle50.out 2> outputs/102/beagle50.err &
  
```


```{r}
m <- as.matrix(read.table("outputs/102/175-ibs-gl.covMat"))
meta<-meta
eig <- eigen(m)
var<-eig$values/sum(eig$values)
cumvar<-cumsum(eig$values)/sum(eig$values)

head(var)
head(cumvar)
covs<-eig$vectors[,1:3] %>% as_tibble() %>% bind_cols(meta)

text12<-covs %>% select(Sample, Location, V1, V2) %>%
  group_by(Location) %>% summarize(Count=n(), x=mean(V1), y=mean(V2))

covs12<-ggplot(covs) +
  geom_point(aes(x=V1, y=V2, fill=Location), pch=21, alpha=0.75) +
  geom_text_repel(data=text12, aes(x=x, y=y, label=Location), max.overlaps = Inf) +
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = "")) +
  ylab(paste("PC2", " ", round((100*var[2]),2), "%", sep = "")) +
  theme_bw() +
  theme(legend.position="")
covs12
```

```{r}
ggplot(covs%>% filter(Location %in% c("EELR","EURS","NOOK"))) +
  geom_point(aes(x=V1, y=V2, fill=Reads), pch=21, alpha=0.75) +
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = "")) +
  ylab(paste("PC2", " ", round((100*var[2]),2), "%", sep = "")) +
  facet_wrap(.~Location) +
  theme_bw()
```
```{r}

text13<-covs %>% select(Sample, Location, V1, V3) %>%
  group_by(Location) %>% summarize(Count=n(), x=mean(V1), y=mean(V3))

covs13<-ggplot(covs) +
  geom_point(aes(x=V1, y=V3, fill=Location), pch=21, alpha=0.75) +
  geom_text_repel(data=text13, aes(x=x, y=y, label=Location), max.overlaps = Inf) +
  xlab(paste("PC1", " ", round((100*var[1]),2), "%", sep = "")) +
  ylab(paste("PC3", " ", round((100*var[3]),2), "%", sep = "")) +
  theme_bw()
covs13
``` 

    
```{r}
ggarrange(covs12, covs13, widths=c(1,1.3))
ggsave("outputs/104/longfin175-ibs-pc123.jpeg", width=10, height=5)

```
## Read Counts


```{r}
existing<-read_tsv("meta/counts.tsv") %>% filter(Alignment !="Original")
existing<-existing %>% filter(Alignment=="New Genome") %>% filter(Reads > 1.5e5) %>%
  mutate(Path=paste0("/home/maccamp/data/longfin/",File))

ggplot(existing) + geom_histogram(aes(x=Reads))
```

```{r}
new<-read_csv("outputs/102/newseq.dat", col_names = c("Sample","Sort","Dedup"))

ggplot(new) + geom_histogram(aes(x=Dedup))
```

```{r}
merge<-existing %>% select(Sample, Reads) %>% mutate(Origin="Existing") %>%
  bind_rows(select(new, Sample, Dedup) %>% rename(Reads=Dedup) %>% mutate(Origin="New Sequencing"))

ggplot(merge, aes(fill=Origin)) + geom_histogram(aes(x=Reads)) +
  theme_bw() +
  scale_fill_viridis_d(option="H") +
  facet_wrap(.~Origin, ncol=1) +
  ylab("Count")

ggsave("outputs/104/longfin-counts.jpeg", width=6, height=4)

``` 

```{r}
quants<-read_csv("meta/original-quants.csv") %>% mutate(DNA="Starting")
conc<-read_csv("meta/concentrated-quants.csv") %>% rename(Samples=SampleID,`conc ng/ul` = `Conc ng/ul`) %>% mutate(DNA="Concentrated")
quants<-bind_rows(quants, conc)
quants

quants$Samples<-gsub(" ","-",quants$Samples)

quants<-new %>% left_join(quants, by=c("Sample"="Samples"))

ggplot(quants %>% filter(DNA=="Concentrated"), aes(x=`conc ng/ul`, y=Dedup)) +
  geom_point(pch=21, alpha=0.75, color="black", fill="black") +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  ylab("Reads Remaining for Analyses\n") +
  xlab("\nConcentration of DNA in ng/ul") +
  geom_hline(aes(yintercept=1.5e5), lty=2)

ggsave("outputs/104/dna-reads.jpeg", width=6, height=4)
```

Droop out nooksack     

```{r}

ggplot(quants[!startsWith(quants$Sample, "Nksk"),] %>% filter(DNA=="Concentrated"), aes(x=`conc ng/ul`, y=Dedup)) +
  geom_point(pch=21, alpha=0.75, color="black", fill="black") +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  ylab("Reads Remaining for Analyses\n") +
  xlab("\nConcentration of DNA in ng/ul") +
  geom_hline(aes(yintercept=1.5e5), lty=2)

ggsave("outputs/104/dna-reads-no-nooksack.jpeg", width=6, height=4)
```


## What about those other species of smelts??

~/data/forage-fishes symlinking some to ~/longfin/data/forage-fishes    
EULN_006, 007, 010     
WAKS 010, 011, 012    
14 DSM (can downsample)

There is no mtDNA in reference, dang.  How to figure out mystery fish from phylogeny? Blast to mtDNA, make new reference for mtDNA???

No H. transpacificus, no A. elongatus, No S. starksi, No S. thaleichthys (S. lanceolatus) exists.   


Align reference EULN WAKS DSM

```{sh, eval=FALSE}
# in data/forage-fish
ls | grep R1 | perl -pe 's/.fastq//g' > forward
ls | grep R2 | perl -pe 's/.fastq//g' > reverse
ls | grep R1 | perl -pe 's/_R1.fastq//g' > name
paste forward reverse name  > samples.txt
bash $HOME/missouri-trout/doAlign-unzipped.sh samples.txt /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa 
```    

(Can include some Longfin)
ALVS_097_R1.sort.flt.bam 
ALVS_098_R1.sort.flt.bam
CHPI_707_R1.sort.flt.bam
HUMB_004_R1.sort.flt.bam
HUMB_005_R1.sort.flt.bam
HUMB_006_R1.sort.flt.bam
SUIB_033_R1.sort.flt.bam
SUIB_044_R1.sort.flt.bam
YBAK_003_R1.sort.flt.bam
YBAK_007_R1.sort.flt.bam
COLR_030_R1.sort.flt.bam

```{r}
refs<-read_csv("outputs/102/forage-fishes.dat", col_names = c("Sample","Sort","Dedup")) %>% 
  mutate(Path=paste0("data/forage-fishes/",Sample,".sort.flt.bam"))

ggplot(refs) +
  geom_histogram(aes(x=Dedup))
```

Mystery fish:
(base) maccamp@farm:~/longfin/data$ cat ./alt-1/alt-1.dat ./alt-2/alt-2.dat ./alt-3/alt-3.dat > alt.dat

```{r}
dat<-read_csv("outputs/104/alt.dat", col_names = c("Sample","Sort","Dedup"))

ggplot(dat) +
  geom_histogram(aes(x=Dedup))
```

Making calls with phylogeny, want quite a few reads
```{r}
ds<-dat %>% filter(Dedup > 5e5) %>% mutate(Path=paste0("data/alt-bams/",Sample,".sort.flt.bam"))
nrow(ds)
```


```{r}
combine<-bind_rows(refs,ds)
write_csv(combine,"outputs/102/combine.csv")
```

```{r}
m216<-read_csv("meta/216.csv")
write_tsv(m216 %>% select(Path), col_names = FALSE, file="bamlists/216.bamlist")
write_tsv(m216 %>% select(Sample), col_names = FALSE, file="bamlists/216.samples")

```



```{sh, eval=FALSE}
srun -p high -t 18:00:00 --mem=16G --nodes=1 angsd -P 24 \
-bam bamlists/216.bamlist \
-out /home/maccamp/longfin/outputs/104/plink \
-anc /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
-rf $HOME/delta-smelt/metadata/large-contigs.txt  \
-minInd 195 -minMaf 0.05  -minMapQ 10 -minQ 20 -GL 1 -doMajorMinor 1 -doMaf 1 -SNP_pval 1e-6 \
-doGeno 4 -doPost 1 -postCutoff 0.95 -doPlink 2 >outputs/104/std.out 2>outputs/104/std.err &
```     

	-> Number of sites retained after filtering: 100035 

## Process


```{sh, eval=FALSE}
plink --tped plink.tped --tfam plink.tfam  --out binary --recode --allow-extra-chr --noweb
plink --ped binary.ped --map binary.map --recode vcf --allow-extra-chr -out recode
bcftools +prune -l 0.25 -w 10000 recode.vcf  -Ov -o recode.prune.vcf
bcftools reheader --samples ../../bamlists/216.samples -o recode.prune.reheadered.vcf recode.prune.vcf

```

After pruning, 7380 snps

onvert to phylip, then nexus. Create a missing data set

```{sh, eval=FALSE}
source activate py2; ~/github/mccloud-rrt/vcf2phylip.py -i recode.prune.reheadered.vcf; conda deactivate;
seqConverter.pl -drecode.prune.reheadered.min4.phy -on

#Corrected for ascertainment bias
conda activate py3; ~/github/mccloud-rrt/103-remove-invariant.py -p recode.prune.reheadered.min4.phy -o recode.prune.reheadered.min4.asc.phy; conda deactivate

seqConverter.pl -drecode.prune.reheadered.min4.asc.phy -on

#Now remove missing?? 
 ~/github/relict-dace/201.1-removeMissing.pl recode.prune.reheadered.min4.asc.phy  > filtered.phy
seqConverter.pl -dfiltered.phy -on

Our dumped samples are DELS, WAKS and EULN. 
```

Local test:

```{sh, eval=FALSE}
seqConverter.pl -drecode.prune.reheadered.min4.asc.phy -of
selectSites.pl -s 1-1000 recode.prune.reheadered.min4.asc.fasta  > sub.fasta
seqConverter.pl -dsub.fasta -ope
iqtree -s sub.phylip -st DNA -m GTR+F+ASC -bb 1000 -alrt 1000 -redo

```

Removed some low quality samples from dumpers (DELS 710 733, an ALVS sample, now 213 samples)
iqtree -s align.phy -st DNA -m GTR+F+ASC -bb 1000 -alrt 1000 -redo
iqtree -s align.phy.varsites.phy -st DNA -m GTR+F+ASC -bb 1000 -alrt 1000 -redo

-T 2 (two cores available apparently)    

```{sh, eval=FALSE}
srun -p high -t 5:00:00 --nodes=1 iqtree -s align.phy.varsites.phy -st DNA -m MFP+ASC -bb 1000 -alrt 1000 -T AUTO -redo
```

## Get samples by species

```{r}
snps<-read.vcfR("outputs/104/recode.prune.reheadered.vcf")
gen<-vcfR2genind(snps)
```

```{r}
x<- tab(gen, NA.method="mean")
pca <- dudi.pca(x,scannf=FALSE,scale=FALSE,nf=5)
plot(pca$li)
```


```{r}
d<- pca$l1 %>% as_tibble()
d$Sample<-rownames(pca$l1)

#Pull out cumulative variance
eig<-pca$eig
sum<-sum(eig)
var<-(eig/sum)*100

d<- d %>% left_join(m216)

#text<-dsba %>% group_by(`River Basin`) %>% mutate(meanx=mean(RS1), meany=mean(RS2)) %>% 
 # select(`River Basin`, meanx, meany) %>% unique()

pc12<-ggplot(d) +
  geom_point(aes(x=RS1, y=RS2), pch=21, alpha=0.75, fill="black") +
#  geom_label_repel(data=text, aes(x=meanx, y=meany, label=`River Basin`),
  #                 fill="white", max.overlaps = Inf, alpha=0.9) +
  #scale_fill_viridis_d(option="H") +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  theme(legend.position = "") +
  xlab(paste0("PC1"," ",round(var[1],2),"%")) +
  ylab(paste0("PC2"," ",round(var[2],2),"%")) 

pc12
```    
```{r}
longs<-d %>% filter(RS1 >0)
other<-d %>% filter(RS1 <0) %>% filter(!(Sample %in% c("DELS_710","DELS_733")))
```
Removed some low quality samples from dumpers (DELS 710 733, an ALVS sample, now 213 samples)     

```{r}
ggplot(other, aes(x=RS1, y=RS2)) +
  geom_point(pch=21, alpha=0.5, fill="black") + geom_text_repel(aes(label=Sample), max.overlaps = Inf)
ggsave("outputs/104/smelts.pdf", width=22, height=22)
```   

Create a bamllist of reference samples

```{r}
ls<-c("ALVS_098_R1","CHPI_707_R1","HUMB_004_R1","HUMB_005_R1","HUMB_006_R1","SUIB_033_R1","SUIB_044_R1","YBAK_003_R1","YBAK_007_R1","COLR_030_R1") %>%
  as_tibble() %>% rename(Sample=value)

smelts<-select(other, Sample) %>% bind_rows(ls)
m72<-smelts %>% left_join(m216)
write_tsv(m72 %>% select(Path), file="bamlists/72.bamlist")
write_tsv(m72 %>% select(Sample), file="bamlists/72.samples")
```

```{sh, eval=FALSE}
srun -p high -t 18:00:00 --mem=16G --nodes=1 angsd -P 24 \
-bam bamlists/216.bamlist \
-out /home/maccamp/longfin/outputs/104/refs/plink \
-anc /home/maccamp/genomes/hypomesus-20210204/Hyp_tra_F_20210204.fa \
-rf $HOME/delta-smelt/metadata/large-contigs.txt  \
-minInd 65 -minMaf 0.05  -minMapQ 10 -minQ 20 -GL 1 -doMajorMinor 1 -doMaf 1 -SNP_pval 1e-6 \
-doGeno 4 -doPost 1 -postCutoff 0.95 -doPlink 2 >outputs/104/refs/std.out 2>outputs/104/refs/std.err &
```

